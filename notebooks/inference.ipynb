{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains helper functions related to inference and evaluation of the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data import *\n",
    "from utils.loss import *\n",
    "from utils.model import *\n",
    "from utils.train import *\n",
    "from utils.plots import *\n",
    "from utils.util import *\n",
    "\n",
    "#import tensorboardX as tb\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data to get the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42) \n",
    "\n",
    "reduced_data=load_and_process_data(mode='dna_gpn_esm2', lower_threshold=10, na_upper_threshold=100, protein_upper_threshold=1000, dataset_dir = '../data/')\n",
    "\n",
    "protein_seqs = [i['protein_seq'] for i in reduced_data]\n",
    "na_seqs = [i['dna_seq'] for i in reduced_data]\n",
    "contact_maps = [torch.tensor(i['complex_contact_map']).T for i in reduced_data]\n",
    "pdb_ids = [i['pdb_id'] for i in reduced_data]\n",
    "\n",
    "train_dset, eval_dset = sequence_similarity_split(reduced_data, mode='dna')\n",
    "eval_dataloader = DataLoader(eval_dset, batch_size=1, shuffle=False, collate_fn=collate_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model (NOTE: Replace 'path' with the actual paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model_q = 320\n",
    "d_model_kv = 512\n",
    "d_k = 32 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "protein_model = ESMModel().to(device)\n",
    "na_model = GPNModel().to(device)\n",
    "binding_model = CustomCrossAttention(d_model_q, d_model_kv, d_k).to(device)\n",
    "\n",
    "checkpoint = torch.load('path', map_location=device)\n",
    "\n",
    "protein_model.model.load_state_dict(checkpoint['protein_model_state_dict'])\n",
    "na_model.model.load_state_dict(checkpoint['na_model_state_dict'])\n",
    "binding_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get predictions and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = eval_dataloader\n",
    "\n",
    "protein_model.eval()\n",
    "na_model.eval()\n",
    "binding_model.eval()\n",
    "\n",
    "#predictions = []\n",
    "visualizer_data = []\n",
    "total_loss_eval = 0\n",
    "total_f1_eval = 0\n",
    "total_prauc_eval = 0\n",
    "total_mcc_eval = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "            for protein_seqs, na_seqs, contact_maps, pdb_id in dl:\n",
    "                protein_seqs = [('', i) for i in protein_seqs]\n",
    "                protein_embeddings = protein_model(protein_seqs)  # List of tensors of shape (L, d_model)\n",
    "                na_embeddings = na_model(na_seqs)  # List of tensors of shape (L, d_model)\n",
    "                padded_protein_embeddings, padded_na_embeddings, padded_contact_maps, protein_lengths, rna_lengths = collate_embeddings(protein_embeddings, na_embeddings, contact_maps)\n",
    "                padded_protein_embeddings, padded_na_embeddings = padded_protein_embeddings.to(device), padded_na_embeddings.to(device)\n",
    "                mask = create_mask(protein_lengths, rna_lengths, padded_protein_embeddings.size(1), padded_na_embeddings.size(1)).unsqueeze(1).float().to(device)\n",
    "\n",
    "                output, predicted_attention = binding_model(padded_protein_embeddings, padded_na_embeddings, mask)\n",
    "\n",
    "                loss = weighted_bce_loss(predicted_attention, padded_contact_maps.squeeze(), mask, pos_weight=None)\n",
    "                total_loss_eval += loss.item()\n",
    "                batch_f1, batch_prauc, batch_mcc = get_batch_metrics(padded_contact_maps.cpu().numpy(), predicted_attention.detach().cpu().numpy(), protein_lengths, rna_lengths)\n",
    "\n",
    "                total_f1_eval += batch_f1\n",
    "                total_prauc_eval += batch_prauc\n",
    "                total_mcc_eval += batch_mcc\n",
    "                visualizer_data.append((padded_contact_maps, predicted_attention.detach(), protein_lengths, rna_lengths, pdb_id))\n",
    "\n",
    "          \n",
    "\n",
    "print('Total Loss: ', total_loss_eval/len(dl)) \n",
    "print('Total F1: ', total_f1_eval/len(dl))\n",
    "print('Total PRAUC: ', total_prauc_eval/len(dl))\n",
    "print('Total MCC: ', total_mcc_eval/len(dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to plot GT, Pred and Overlays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_attention_maps(gt_attention, predicted_attention, protein_len, rna_len,pdb_id,plot=True):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 40), constrained_layout=True)\n",
    "    predicted_attention = predicted_attention.squeeze(0).cpu().numpy()\n",
    "    gt_attention = gt_attention.squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Transpose the attention maps to flip the axes\n",
    "    gt_attention = gt_attention.T\n",
    "    predicted_attention = predicted_attention.T\n",
    "\n",
    "    # Ground Truth Contact Map\n",
    "    ax = axes[0]\n",
    "    cax = ax.matshow(gt_attention[:rna_len, :protein_len], cmap='viridis')\n",
    "    ax.set_title(f'GT')\n",
    "    ax.set_xlabel('Protein Seq')\n",
    "    ax.set_ylabel('NA Seq')\n",
    "\n",
    "    # Overlay Plot\n",
    "    ax = axes[1]\n",
    "    overlay = np.ones((rna_len, protein_len, 3))\n",
    "    for i in range(rna_len):\n",
    "        for j in range(protein_len):\n",
    "            if gt_attention[i, j] > 0.5 and predicted_attention[i, j] > 0.5:\n",
    "                overlay[i, j] = [0, 0, 0]  # Purple for matching non-zero points\n",
    "            elif gt_attention[i, j] > 0.5 and predicted_attention[i, j] <= 0.5:\n",
    "                overlay[i, j] = [0, 0, 1]  # Blue for ground truth contacts\n",
    "            elif gt_attention[i, j] <= 0.5 and predicted_attention[i, j] > 0.5:\n",
    "                overlay[i, j] = [1, 0, 0]  # Red for incorrect predictions\n",
    "    ax.imshow(overlay)\n",
    "    ax.set_title(f'Overlay:{pdb_id}')\n",
    "    ax.set_xlabel('Protein Seq')\n",
    "    ax.set_ylabel('NA Seq')\n",
    "\n",
    "    # Predicted Contact Map\n",
    "    ax = axes[2]\n",
    "    cax = ax.matshow(predicted_attention[:rna_len, :protein_len], cmap='viridis')\n",
    "    ax.set_title('Pred')\n",
    "    ax.set_xlabel('Protein Seq')\n",
    "    ax.set_ylabel('NA Seq')\n",
    "\n",
    "    # Adjust spacing between plots\n",
    "    if not plot:\n",
    "        plt.close()\n",
    "        return fig\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse and Plot metrics from Tensorboard Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "def extract_scalars_from_event_file(event_file):\n",
    "    event_acc = EventAccumulator(event_file)\n",
    "    event_acc.Reload()\n",
    "    \n",
    "    scalars = {}\n",
    "    for tag in event_acc.Tags()['scalars']:\n",
    "        scalars[tag] = event_acc.Scalars(tag)\n",
    "    \n",
    "    return scalars\n",
    "\n",
    "def plot_all(scalars, output_dir, save=False):\n",
    "    # Plot CL Metrics\n",
    "    metrics = ['Metrics/F1', 'Metrics/PR_AUC', 'Metrics/MCC']\n",
    "    phases = ['', 'Eval']  # '' for train phase, 'Eval' for evaluation phase\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(9, 5), constrained_layout=True)\n",
    "    for j, metric in enumerate(metrics):\n",
    "        for i, phase in enumerate(phases):\n",
    "            tag = f\"{metric}/{phase}\" if phase else metric\n",
    "            \n",
    "            if tag in scalars:\n",
    "                values = scalars[tag]\n",
    "                steps = [x.step for x in values]\n",
    "                scalar_values = [x.value for x in values]\n",
    "\n",
    "                ax = axes[i, j]\n",
    "                ax.plot(steps, scalar_values, label=tag)\n",
    "                ax.set_xlabel('Epochs')\n",
    "                ax.set_ylabel(metric.split('/')[-1])\n",
    "                ax.set_title(f'{metric.split(\"/\")[-1]} (Eval)' if phase else f'{metric.split(\"/\")[-1]} (Train)')\n",
    "                ax.legend()\n",
    "    \n",
    "    if save:\n",
    "        output_path = os.path.join(output_dir, \"metrics_plot.png\")\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # Plot Loss\n",
    "    phases = ['Train', 'Eval']\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(9, 5), constrained_layout=True)\n",
    "    for i, phase in enumerate(phases):\n",
    "        tag = f\"Loss/{phase}\"\n",
    "        \n",
    "        if tag in scalars:\n",
    "            values = scalars[tag]\n",
    "            steps = [x.step for x in values]\n",
    "            scalar_values = [x.value for x in values]\n",
    "\n",
    "            ax = axes[i]\n",
    "            ax.plot(steps, scalar_values, label=tag)\n",
    "            ax.set_xlabel('Epochs')\n",
    "            ax.set_ylabel('Loss')\n",
    "            ax.set_title(f'Loss ({phase})')\n",
    "            ax.legend()\n",
    "    \n",
    "    if save:\n",
    "        output_path = os.path.join(output_dir, \"loss_plot.png\")\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    # Plot Gradients\n",
    "    gradients = ['Gradients/Binding_Model', 'Gradients/Protein_Model', 'Gradients/NA_Model']\n",
    "    y_limits = [(0.2, 0.5), (0.125, 0.2), (0.01, 0.02)]  # (lower_limit, upper_limit) for each gradient\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(9, 5), constrained_layout=True)\n",
    "    \n",
    "    for i, gradient in enumerate(gradients):\n",
    "        if gradient in scalars:\n",
    "            values = scalars[gradient]\n",
    "            steps = [x.step for x in values]\n",
    "            scalar_values = [x.value for x in values]\n",
    "\n",
    "            # Filter out epoch 0\n",
    "            steps_filtered = [step for step in steps if step > 0]\n",
    "            scalar_values_filtered = [scalar_values[j] for j, step in enumerate(steps) if step > 0]\n",
    "\n",
    "            ax = axes[i]\n",
    "            ax.plot(steps_filtered, scalar_values_filtered, label=gradient)\n",
    "            ax.set_xlabel('Epochs')\n",
    "            ax.set_ylabel('Gradient')\n",
    "            ax.set_title(f'{gradient.split(\"/\")[-1]}')\n",
    "            ax.set_ylim(y_limits[i])\n",
    "            ax.legend()\n",
    "    \n",
    "    if save:\n",
    "        output_path = os.path.join(output_dir, \"gradients_plot.png\")\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars=extract_scalars_from_event_file('path')\n",
    "plot_all(scalars, 'path', save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
