{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download your AF3 predictions and convert them to PDB/parse them in MMCIF form, and extract contact maps from them\n",
    "#### The evaluation pipeline expects pairs of GT and AF3 contact maps which have been indexed using indices calculated below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "The longest_common_substring_indices function aligns sequences of the structures and the FASTA sequences for the most accurate comparison. (See https://www.biostars.org/p/9588718/#9588721 for more details)\n",
    "\n",
    "'''\n",
    "\n",
    "def longest_common_substring_indices(s1, s2):\n",
    "    m, n = len(s1), len(s2)\n",
    "    \n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    length = 0 \n",
    "    end_idx_s1 = 0  \n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                if dp[i][j] > length:\n",
    "                    length = dp[i][j]\n",
    "                    end_idx_s1 = i - 1\n",
    "\n",
    "    start_idx_s1 = end_idx_s1 - length + 1\n",
    "\n",
    "    common_substring_s2 = s1[start_idx_s1:end_idx_s1 + 1]\n",
    "    start_idx_s2 = s2.find(common_substring_s2)\n",
    "    \n",
    "    return (start_idx_s1, end_idx_s1), (start_idx_s2, start_idx_s2 + length - 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_net_metrics(pdbs, matrix_pairs):\n",
    "    all_preds = []\n",
    "    all_truths = []\n",
    "    all_pdbs = []\n",
    "    \n",
    "    for pdb, _, _, _ in pdbs:\n",
    "        all_pdbs.append(pdb)\n",
    "        for M1, M2, pdb_id in matrix_pairs:\n",
    "            if pdb == pdb_id:\n",
    "                L_overlap = min(M1.shape[0], M2.shape[0])\n",
    "                N_overlap = min(M1.shape[1], M2.shape[1])\n",
    "\n",
    "                submatrix1 = M1[:L_overlap, :N_overlap].flatten()\n",
    "                submatrix2 = M2[:L_overlap, :N_overlap].flatten()\n",
    "\n",
    "                all_preds.extend(submatrix1)\n",
    "                all_truths.extend(submatrix2)\n",
    "                break\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_truths = np.array(all_truths)\n",
    "\n",
    "    net_f1 = f1_score(all_truths, all_preds, average='binary')\n",
    "    net_mcc = matthews_corrcoef(all_truths, all_preds)\n",
    "    precision, recall, _ = precision_recall_curve(all_truths, all_preds)\n",
    "    net_pr_auc = auc(recall, precision)\n",
    "\n",
    "    return net_f1, net_mcc, net_pr_auc, all_pdbs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Baseline\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, precision_recall_curve, auc\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.data import *\n",
    "\n",
    "random_baseline = load_and_process_data(mode='dna', lower_threshold=10, na_upper_threshold=100, protein_upper_threshold=1000, dataset_dir='../data')\n",
    "\n",
    "all_contacts = []\n",
    "for elem in random_baseline:\n",
    "    all_contacts.append(elem[\"complex_contact_map\"])\n",
    "\n",
    "sum_contacts = 0\n",
    "total_elems = 0\n",
    "\n",
    "for map in all_contacts:\n",
    "    sum_contacts += np.sum(map)\n",
    "    total_elems += map.shape[0]*map.shape[1]\n",
    "    \n",
    "\n",
    "train_data, eval_data = sequence_similarity_split(random_baseline, split_path='../mmseq2/train_test_clusters.pkl', mode='dna')\n",
    "\n",
    "\n",
    "def run_random_baseline(Cmaps):\n",
    "    total_positives = 0\n",
    "    total_elems = 0\n",
    "\n",
    "    #  Calculate p_success\n",
    "    for cmap in Cmaps:\n",
    "        total_positives += np.sum(cmap)\n",
    "        total_elems += cmap.shape[0] * cmap.shape[1]\n",
    "\n",
    "    p_success = total_positives / total_elems\n",
    "\n",
    "    # Create a Bernoulli distribution with p_success\n",
    "    bernoulli = np.random.binomial(1, p_success, size=total_elems)\n",
    "\n",
    "\n",
    "    f1_scores = []\n",
    "    mcc_scores = []\n",
    "    pr_aucs = []\n",
    "\n",
    "    for cmap in Cmaps:\n",
    "        random_cmap = bernoulli[:cmap.size].reshape(cmap.shape)\n",
    "        bernoulli = bernoulli[cmap.size:]  \n",
    "\n",
    "        original_flat = cmap.flatten()\n",
    "        random_flat = random_cmap.flatten()\n",
    "\n",
    "        f1 = f1_score(original_flat, random_flat)\n",
    "        f1_scores.append(f1)\n",
    "        mcc = matthews_corrcoef(original_flat, random_flat)\n",
    "        mcc_scores.append(mcc)\n",
    "        precision, recall, _ = precision_recall_curve(original_flat, random_flat)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        pr_aucs.append(pr_auc)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'F1': np.mean(f1_scores),\n",
    "        'MCC': np.mean(mcc_scores),\n",
    "        'PR-AUC': np.mean(pr_aucs)\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caltek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
